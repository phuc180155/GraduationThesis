{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/anaconda3/envs/phucnp/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torchvision.models import vgg19\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# use the ImageNet transformation\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# define a 1 image dataset\n",
    "dataset = datasets.ImageFolder(root='/mnt/disk1/doan/phucnp/Graduation_Thesis/my_thesis/forensics/dl_technique/CAM/data', transform=transform)\n",
    "\n",
    "# define the dataloader to load that single image\n",
    "dataloader = data.DataLoader(dataset=dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        \n",
    "        # get the pretrained VGG19 network\n",
    "        self.vgg = vgg19(pretrained=True)\n",
    "        \n",
    "        # disect the network to access its last convolutional layer\n",
    "        self.features_conv = self.vgg.features[:36]\n",
    "        \n",
    "        # get the max pool of the features stem\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        \n",
    "        # get the classifier of the vgg19\n",
    "        self.classifier = self.vgg.classifier\n",
    "        \n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "    \n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features_conv(x)\n",
    "        \n",
    "        # register the hook\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        # apply the remaining pooling\n",
    "        x = self.max_pool(x)\n",
    "        x = x.view((1, -1))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the VGG model\n",
    "vgg = VGG()\n",
    "\n",
    "# set the evaluation mode\n",
    "vgg.eval()\n",
    "\n",
    "# get the image from the dataloader\n",
    "img, _ = next(iter(dataloader))\n",
    "\n",
    "# get the most likely prediction of the model\n",
    "pred = vgg(img)\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8053216a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the gradient of the output with respect to the parameters of the model\n",
    "pred[:, 386].backward()\n",
    "\n",
    "# pull the gradients out of the model\n",
    "gradients = vgg.get_activations_gradient()\n",
    "\n",
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "# get the activations of the last convolutional layer\n",
    "activations = vgg.get_activations(img).detach()\n",
    "\n",
    "# weight the channels by corresponding gradients\n",
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "# normalize the heatmap\n",
    "heatmap /= torch.max(heatmap)\n",
    "\n",
    "# draw the heatmap\n",
    "plt.matshow(heatmap.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('/mnt/disk1/doan/phucnp/Graduation_Thesis/my_thesis/forensics/dl_technique/CAM/data/Elephant/elephant_1.png')\n",
    "heatmap = heatmap.cpu().detach().numpy()\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('./map.jpg', superimposed_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('phucnp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73e4523d5c5fcabc881bfbabdc03d28b885253c65d62f8f3eb31939c7679911f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/anaconda3/envs/phucnp/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/disk1/doan/phucnp/Graduation_Thesis/my_thesis/forensics/preprocess_data', '/mnt/disk1/anaconda3/envs/phucnp/lib/python38.zip', '/mnt/disk1/anaconda3/envs/phucnp/lib/python3.8', '/mnt/disk1/anaconda3/envs/phucnp/lib/python3.8/lib-dynload', '', '/mnt/disk1/doan/.local/lib/python3.8/site-packages', '/mnt/disk1/anaconda3/envs/phucnp/lib/python3.8/site-packages']\n",
      "Paths:  800\n",
      "Video name:  270_297\n",
      "Number of taken frame: 12\n",
      "Video name:  923_023\n",
      "Number of taken frame: 22\n",
      "Video name:  776_676\n",
      "Number of taken frame: 13\n",
      "Video name:  985_981\n",
      "Number of taken frame: 13\n",
      "Video name:  631_551\n",
      "Number of taken frame: 16\n",
      "Video name:  262_301\n",
      "Number of taken frame: 15\n",
      "Video name:  800_840\n",
      "Number of taken frame: 13\n",
      "Video name:  671_677\n",
      "Number of taken frame: 12\n",
      "Video name:  937_888\n",
      "Number of taken frame: 12\n",
      "Video name:  493_538\n",
      "Number of taken frame: 15\n",
      "Video name:  428_466\n",
      "Number of taken frame: 13\n",
      "Video name:  514_443\n",
      "Number of taken frame: 14\n",
      "Video name:  791_770\n",
      "Number of taken frame: 13\n",
      "Video name:  303_309\n",
      "Number of taken frame: 22\n",
      "Video name:  535_587\n",
      "Number of taken frame: 25\n",
      "Video name:  879_963\n",
      "Number of taken frame: 27\n",
      "Video name:  967_984\n",
      "Number of taken frame: 13\n",
      "Video name:  679_665\n",
      "Number of taken frame: 12\n",
      "Video name:  498_433\n",
      "Number of taken frame: 12\n",
      "Video name:  282_238\n",
      "Number of taken frame: 23\n",
      "Video name:  299_145\n",
      "Number of taken frame: 12\n",
      "Video name:  438_434\n",
      "Number of taken frame: 13\n",
      "Video name:  886_877\n",
      "Number of taken frame: 21\n",
      "Video name:  774_735\n",
      "Number of taken frame: 12\n",
      "Video name:  345_259\n",
      "Number of taken frame: 16\n",
      "Video name:  509_525\n",
      "Number of taken frame: 20\n",
      "Video name:  863_853\n",
      "Number of taken frame: 20\n",
      "Video name:  309_303\n",
      "Number of taken frame: 22\n",
      "Video name:  614_616\n",
      "Number of taken frame: 20\n",
      "Video name:  629_618\n",
      "Number of taken frame: 14\n",
      "Video name:  577_593\n",
      "Number of taken frame: 13\n",
      "Video name:  416_342\n",
      "Number of taken frame: 12\n",
      "Video name:  253_183\n",
      "Number of taken frame: 15\n",
      "Video name:  802_885\n",
      "Number of taken frame: 13\n",
      "Video name:  454_527\n",
      "Number of taken frame: 13\n",
      "Video name:  772_708\n",
      "Number of taken frame: 13\n",
      "Video name:  900_926\n",
      "Number of taken frame: 13\n",
      "Video name:  877_886\n",
      "Number of taken frame: 21\n",
      "Video name:  205_184\n",
      "Number of taken frame: 12\n",
      "Video name:  497_403\n"
     ]
    }
   ],
   "source": [
    "from ast import parse\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "import glob\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "from facenet_pytorch import MTCNN\n",
    "from utils import *\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# torch.multiprocessing.set_start_method('spawn')\n",
    "device = torch.device('cpu' if torch.cuda.is_available() else 'cuda')\n",
    "face_detector = MTCNN(device=device)\n",
    "\n",
    "fake_image_dir = \"../../../../2_Deep_Learning/Dataset/facial_forgery/FF+/image/fake\"\n",
    "fake_video_dir = \"../../../../2_Deep_Learning/Dataset/facial_forgery/FF+/manipulated_sequences\"\n",
    "real_image_dir = \"../../../../2_Deep_Learning/Dataset/facial_forgery/FF+/image/real\"\n",
    "real_video_dir = \"../../../../2_Deep_Learning/Dataset/facial_forgery/FF+/original_sequences\"\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Fake Detection\")\n",
    "    parser.add_argument('--in_dir', default='', help='path to train data')\n",
    "    parser.add_argument('--out_dir', default='out', help='path to test data')\n",
    "    parser.add_argument('--num_thread', default=4, type=int, help='number of threads')\n",
    "    parser.add_argument('--duration', default=15, type=int)\n",
    "    return parser.parse_args()\n",
    "\n",
    "def extract_frame(video_path):\n",
    "    # \n",
    "    output_dir = out_dir\n",
    "    duration = durationss\n",
    "\n",
    "    # Đọc video với videoCapture\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    video_name = osp.basename(video_path).split('.')[0]\n",
    "\n",
    "    print(video_name)\n",
    "    print(video)\n",
    "\n",
    "    success = True\n",
    "    image = None\n",
    "    id_frame = 0\n",
    "    \n",
    "    while success:\n",
    "        # Đọc video 4 lần (4 frame), chỉ lấy frame cuối cùng, nếu fail thì kết thúc vòng lặp\n",
    "        for i in range(duration):\n",
    "            success, image = video.read()\n",
    "            if not success:\n",
    "                break\n",
    "            \n",
    "        print(\"Get here\")\n",
    "        print(\"Success: \", success)\n",
    "        print(\"Image: \\n\", image)\n",
    "        try:\n",
    "            # Convert from BGR (CV) to RGB (Image)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        plt.imsave(osp.join(output_dir, video_name + '_' + str(id_frame) + '.jpg'), image, format='jpg')\n",
    "        id_frame += 1\n",
    "        \n",
    "\n",
    "def extract_face(video_path: str, ext_margin=0.2):\n",
    "    #\n",
    "    # forgery_tech = video_path.split('/')[-4]\n",
    "    output_dir = out_dir if out_dir != '' else real_image_dir\n",
    "    duration = durationss\n",
    "    # Read video:\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    video_name = osp.basename(video_path).split('.')[0]\n",
    "\n",
    "    # print(\"Forgery Tech: \", forgery_tech)\n",
    "    print(\"Video name: \", video_name)\n",
    "    # if not osp.exists(osp.join(output_dir, forgery_tech)):\n",
    "    #     os.mkdir(osp.join(output_dir, forgery_tech))\n",
    "    #\n",
    "    success = True\n",
    "    image = None\n",
    "    id_frame = 0\n",
    "    while success:\n",
    "        # Read <duration> times, only get the last success if successes for all <duration> times\n",
    "        for _ in range(duration):\n",
    "            success, image = video.read()\n",
    "            if not success:\n",
    "                break\n",
    "        try:\n",
    "            # Convert from BGR to RGB\n",
    "            image = cv2.cvtColor(image, code=cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Detect face:\n",
    "        face_pos, probs = face_detector.detect(image, landmarks=False) \n",
    "        # vis_face_img(image, face_pos[0], probs[0], landmark=None, vis=False, save=None)\n",
    "\n",
    "        # Find the face with largest prob \n",
    "        try:\n",
    "            face_pos = face_pos[np.argmax(probs)]\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        # Extend face rectangle\n",
    "        xmin, ymin, xmax, ymax = face_pos\n",
    "        x, y, w, h = map(int, [xmin, ymin, xmax-xmin, ymax-ymin])\n",
    "        extend_x, extend_y = int(w * ext_margin), int(h * ext_margin)\n",
    "        xmin = max(0, x - extend_x)\n",
    "        ymin = max(0, y - extend_y)\n",
    "        xmax = min(image.shape[1], x + w + extend_x)\n",
    "        ymax = min(image.shape[0], y + h + extend_y)\n",
    "\n",
    "        face = image[ymin:ymax, xmin:xmax]\n",
    "        # Save to output dir:\n",
    "        plt.imsave(osp.join(output_dir, 'faceswap_' + video_name + '_' + str(id_frame) + '.jpg'), face, format='jpg')\n",
    "        # plt.imsave(osp.join(output_dir, video_name + '_' + str(id_frame) + '.jpg'), face, format='jpg')\n",
    "\n",
    "        id_frame += 1\n",
    "    print(\"Number of taken frame: {}\".format(id_frame))\n",
    "\n",
    "\n",
    "# args = parse_args()\n",
    "### Step 1: Giải quyết real:\n",
    "#    +) Tách 800 video train/200 video test.\n",
    "#    +) Extract ra image.\n",
    "#    +) Đặt vào all/deepfake/f2f/fs/nt train/0_real - 800 và test/0_real - 200\n",
    "### Step 2: Giải quyết fake:\n",
    "#   +) Với mỗi technique fake, tách ra 800/200: train/1_df - test/1_df\n",
    "#   +) Extract tương ứng cho từng technique\n",
    "#   +) Gộp lại đặt trong all\n",
    "in_dir = '/mnt/disk1/doan/phucnp/Dataset/ff/video/manipulated_sequences/FaceSwap/train'\n",
    "out_dir = \"/mnt/disk1/doan/phucnp/Dataset/ff/video/manipulated_sequences/FaceSwap/image/train\"\n",
    "durationss = 25\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    video_paths = []\n",
    "    video_types = ['/*.mp4', '/*/*/*/*.avi']  # Deepfakes/c23/videos/*.mp4\n",
    "\n",
    "    # Duyệt tất cả các path tới video\n",
    "    for type in video_types:\n",
    "        paths = glob.glob(in_dir + type)\n",
    "        video_paths.extend(paths)\n",
    "\n",
    "    print(\"Paths: \", len(video_paths))\n",
    "\n",
    "    # Sử dụng tính toán đa luồng\n",
    "    for path in video_paths:\n",
    "        extract_face(path)\n",
    "\n",
    "    print(len(os.listdir(\"/mnt/disk1/doan/phucnp/Dataset/ff/video/manipulated_sequences/FaceSwap/image/train\")))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('phucnp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73e4523d5c5fcabc881bfbabdc03d28b885253c65d62f8f3eb31939c7679911f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
